---
title: "XGBoost Model Analysis"
author: "Sindy Du"
output: html_document
---

```{r,results='hide', message=FALSE,echo=FALSE}
library(rgdal)
library(tidyverse)
library(DescTools)
library(lubridate)
library(readr)
library(here)
library(ggplot2)
library(plotly)
library(xgboost)
library(forecast)
library(xtable)
library(gridExtra)
library(rmarkdown)
library(here)
library(readr)
library(dplyr)
library(tidymodels)
library(gridExtra)
library(xtable)
library(keras)
```

Load the observations from 25 locations.

```{r,echo=FALSE,message=FALSE,warning=FALSE}
# load("xgboost_all.rda")
```

Run the following code to get the overall RMSE, monthly RMSE, predictions, and the EPA measurements of the testing set.

```{r,echo=FALSE,message=FALSE,warning=FALSE}
xgboost_model <- function(train_satellite, test_satellite){
    
    # variable names
    features <- setdiff(names(train_satellite), "pmFRM")

    # Create the treatment plan from the training data
    treatplan <- vtreat::designTreatmentsZ(train_satellite, features, verbose = FALSE)

    # Get the "clean" variable names from the scoreFrame
    new_vars <- treatplan %>%
        magrittr::use_series(scoreFrame) %>%        
        dplyr::filter(code %in% c("clean", "lev")) %>% 
        magrittr::use_series(varName)     

    # Prepare the training data
    features_train <- vtreat::prepare(treatplan, train_satellite, 
                                      varRestriction = new_vars) %>% as.matrix()
    response_train <- train_satellite$pmFRM

    # Prepare the test data
    features_test <- vtreat::prepare(treatplan, test_satellite, 
                                     varRestriction = new_vars) %>% as.matrix()
    response_test <- test_satellite$pmFRM

    # dimensions of one-hot encoded data
    dim(features_train)
    dim(features_test)


    set.seed(1234)
    xgb.fit1 <- xgb.cv(
        data = features_train,
        label = response_train,
        nrounds = 1000,
        nfold = 4,
        early_stopping_rounds = 3, # silent,
        verbose = 0
    )

    summary1 <- xgb.fit1$evaluation_log %>%
        dplyr::summarise(
        ntrees.train = which(train_rmse_mean == min(train_rmse_mean))[1],
        rmse.train   = min(train_rmse_mean),
        ntrees.test  = which(test_rmse_mean == min(test_rmse_mean))[1],
        rmse.test   = min(test_rmse_mean))
    

################################################
# the following code takes a while to run      #
# we ran it once and found the best parameters #
# go to Line 184 to see the parameters         #
################################################

#############################################################################################
############################################################################################# 
#                                        BEGIN                                              #
############################################################################################# 
############################################################################################# 
    
    # create a hyperparameter grid: run 243 XGBoost models (3 * 3 * 3 * 3 * 3)
    hyper_grid <- expand.grid(max_depth = seq(6, 10, 2), 
                               eta = seq(.1, .3, .1),
                               min_child_weight = seq(2, 6, 2),
                               subsample = seq(0.6, 1, 0.2),
                               colsample_bytree = seq(0.6, 1, 0.2))  
     
     # grid search 
    for(i in 1:nrow(hyper_grid)) {
   
        # create parameter list
        params <- list(
          eta = hyper_grid$eta[i],
          max_depth = hyper_grid$max_depth[i],
          min_child_weight = hyper_grid$min_child_weight[i],
          subsample = hyper_grid$subsample[i],
          colsample_bytree = hyper_grid$colsample_bytree[i]
        )
  
        # reproducibility
        set.seed(1234)
   
        # train model
        xgb.tune <- xgb.cv(
          params = params,
          data = features_train,
          label = response_train,
          nrounds = 1000,
          nfold = 4,
          objective = "reg:linear",  # for regression models
          verbose = 0,               # silent,
          early_stopping_rounds = 3 # stop if no improvement for 10 consecutive trees
        )
  
        # add min training error and trees to grid
        hyper_grid$optimal_trees[i] <- which.min(xgb.tune$evaluation_log$test_rmse_mean)
        hyper_grid$min_RMSE[i] <- min(xgb.tune$evaluation_log$test_rmse_mean)
 }
    
     # display the best parameter
     best_params <- hyper_grid %>% 
         dplyr::arrange(min_RMSE) %>%
         head(1)

     xgb_train_rmse <- NULL
     xgb_test_rmse <- NULL
     
     for (j in 1:nrow(hyper_grid)) {
         set.seed(1234)
         m_xgb_untuned <- xgb.cv(
             data = features_train,
             label = response_train,
             nrounds = 1000,
             objective = "reg:squarederror",
             early_stopping_rounds = 3,
             nfold = 4,
             max_depth = hyper_grid$max_depth[j],
             eta = hyper_grid$eta[j],
             min_child_weight = hyper_grid$min_child_weight[j],
             subsample = hyper_grid$subsample[j],
             colsample_bytree = hyper_grid$colsample_bytree[j],
             verbose = 0
             )
     
         xgb_train_rmse[j] <- m_xgb_untuned$evaluation_log$train_rmse_mean[m_xgb_untuned$best_iteration]
         xgb_test_rmse[j] <- m_xgb_untuned$evaluation_log$test_rmse_mean[m_xgb_untuned$best_iteration]
     
         cat(j, "\n")
     }
     
     best_params <- hyper_grid[which.min(xgb_test_rmse), ]

     # parameter list
     params <- list(
         max_depth = best_params[1,1],
         eta = best_params[1,2],
         min_child_weight = best_params[1,3],
         subsample = best_params[1,4],
         colsample_bytree = best_params[1,5]
     )
     
#############################################################################################
############################################################################################# 
#                                        END                                                #
############################################################################################# 
############################################################################################# 
     

     
 # best parameters: 8, 0.1, 6, 0.8, 0.8
    params <- list(
        max_depth = 8,
        eta = 0.1,
        min_child_weight = 6,
        subsample = 0.8,
        colsample_bytree = 0.8
    )

    set.seed(1234)
    # train final model
    xgb.fit.final <- xgboost(
        params = params,
        data = features_train,
        label = response_train,
        nrounds = 1000,
        verbose = 0)

    importance_matrix <- xgb.importance(model = xgb.fit.final)

    # predicted values for test data
    pred <- predict(xgb.fit.final, features_test)

    test_satellite_pred <- test_satellite %>% 
        mutate(pred, resid = pred - pmFRM) 


    # RMSE by month
     RMSE_month <- test_satellite_pred %>%
         group_by(month) %>%
         summarise(numObs = n(), meanPM = mean(pmFRM), 
               stdPM = sd(pmFRM),
               RMSE = caret::RMSE(pred, pmFRM)) %>%
         arrange(desc(RMSE)) 

    # results
    result_rmse <- caret::RMSE(pred, response_test)
    result_month <- RMSE_month

    return(list(result_rmse, result_month, pred, test_satellite$pmFRM))
}
```

```{r}
set.seed(123)
satellite_split <- rsample::initial_split(data = all_cities_xgboost, prop = 4/5)
train_set <-rsample::training(satellite_split)
test_set <-rsample::testing(satellite_split)
result <- xgboost_model(train_set, test_set)
```

